{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dERd0xoIHk9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a922ed6-3283-40c2-b249-95b644a58e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/dhruvsaluja/indian-medicinal-plants\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GscV9sCJDJ",
        "outputId": "12a13a8d-0e02-4a34-aaba-e86c64d476a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: dhruvsaluja\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/dhruvsaluja/indian-medicinal-plants\n",
            "Downloading indian-medicinal-plants.zip to ./indian-medicinal-plants\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253M/253M [00:04<00:00, 54.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "input_shape = (150, 150, 3)  # Adjust the image size as needed\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "num_classes = 40  # Number of different plant classes\n",
        "data_dir = \"/content/indian-medicinal-plants/Indian Medicinal Plant Image Datasets/Medicinal plant dataset\"  # Replace with the path to your dataset folder\n"
      ],
      "metadata": {
        "id": "m4XuCP6dCXw9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mxmG1HQCZ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping between class indices and plant names\n",
        "class_mapping = {\n",
        "    0: 'Aloevera',\n",
        "    1: 'Amla',\n",
        "    2: 'Amruta Balli',\n",
        "    3: 'Arali',\n",
        "    4: 'Ashoka',\n",
        "    5: 'Ashwagandha',\n",
        "    6: 'Avacado',\n",
        "    7: 'Bamboo',\n",
        "    8: 'Basale',\n",
        "    9: 'Betel',\n",
        "    10: 'Betel_Nut',\n",
        "    11: 'Brahmi',\n",
        "    12: 'Castor',\n",
        "    13: 'Curry Leaf',\n",
        "    14: 'Doddapatre',\n",
        "    15: 'Ekka',\n",
        "    16: 'Ganike',\n",
        "    17: 'Gauva',\n",
        "    18: 'Geranium',\n",
        "    19: 'Henna',\n",
        "    20: 'Hibiscus',\n",
        "    21: 'Honge',\n",
        "    22: 'Insulin',\n",
        "    23: 'Jasmine',\n",
        "    24: 'Lemon',\n",
        "    25: 'Lemon_grass',\n",
        "    26: 'Mango',\n",
        "    27: 'Mint',\n",
        "    28: 'Nagadali',\n",
        "    29: 'Neem',\n",
        "    30: 'Nithyapushpa',\n",
        "    31: 'Nooni',\n",
        "    32: 'Pappaya',\n",
        "    33: 'Pepper',\n",
        "    34: 'Pomegranate',\n",
        "    35: 'Raktachandini',\n",
        "    36: 'Rose',\n",
        "    37: 'Sapota',\n",
        "    38: 'Tulasi',\n",
        "    39: 'Wood_sorel',\n",
        "    # Add mappings for all 40 classes here\n",
        "}"
      ],
      "metadata": {
        "id": "YXs9ehbmfIBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,     # Normalize pixel values\n",
        "    rotation_range=20,      # Randomly rotate images\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally\n",
        "    height_shift_range=0.2, # Randomly shift images vertically\n",
        "    shear_range=0.2,        # Shear intensity\n",
        "    zoom_range=0.2,         # Randomly zoom in on images\n",
        "    horizontal_flip=True,   # Randomly flip images horizontally\n",
        "    fill_mode='nearest',    # Fill missing pixels with the nearest value\n",
        "    validation_split=0.2     # 20% of data will be used for validation\n",
        ")"
      ],
      "metadata": {
        "id": "LLxbUxxICgW4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and augment training data (80%)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,                 # Root directory containing 40 subfolders\n",
        "    target_size=input_shape[:2],   # Resize images to match input_shape\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Categorical classification\n",
        "    shuffle=True,             # Shuffle the data for training\n",
        "    subset='training'         # Specify training data subset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPZQiDi6Cqn5",
        "outputId": "5ead6752-8d7e-42e1-e1d7-48a611ccb167"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4765 images belonging to 40 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and augment validation data (20%)\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,                 # Root directory containing 40 subfolders\n",
        "    target_size=input_shape[:2],  # Resize images to match input_shape\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Categorical classification\n",
        "    shuffle=False,            # Do not shuffle for validation\n",
        "    subset='validation'       # Specify validation data subset\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeCY9KaUCrBZ",
        "outputId": "1613039d-992a-4e22-bfc6-d5194dc85083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1180 images belonging to 40 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape (modify this according to your input data)\n",
        "input_shape = (150, 150, 3)  # Assuming input images are 224x224 RGB images\n",
        "num_classes = 40  # Define the number of classes in your dataset\n"
      ],
      "metadata": {
        "id": "OU9iFowaHt5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the trained models for inference\n",
        "loaded_model_201 = tf.keras.models.load_model('plant_classification_model_DenseNet121.h5')\n",
        "loaded_model_169 = tf.keras.models.load_model('plant_classification_model_DenseNet169.h5')\n",
        "loaded_model_121 = tf.keras.models.load_model('plant_classification_model_DenseNet201.h5')\n"
      ],
      "metadata": {
        "id": "0KQ5w-NRH1a_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store true labels and predicted labels\n",
        "y_true = []\n",
        "y_pred = []"
      ],
      "metadata": {
        "id": "mMHad6OQHJby"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through the validation generator and make predictions\n",
        "for i in range(len(validation_generator)):\n",
        "    # Get the batch of images and labels\n",
        "    x_batch, y_batch = validation_generator[i]\n",
        "\n",
        "    # Make predictions with the ensemble model\n",
        "    predictions_201 = loaded_model_201.predict(x_batch)\n",
        "    predictions_169 = loaded_model_169.predict(x_batch)\n",
        "    predictions_121 = loaded_model_121.predict(x_batch)\n",
        "\n",
        "    # Combine predictions (simple averaging)\n",
        "    ensemble_predictions = (predictions_201 + predictions_169 + predictions_121) / 3.0\n",
        "\n",
        "    # Get the predicted class indices\n",
        "    predicted_indices = np.argmax(ensemble_predictions, axis=1)\n",
        "\n",
        "    # Append true labels and predicted labels to the lists\n",
        "    y_true.extend(np.argmax(y_batch, axis=1))\n",
        "    y_pred.extend(predicted_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45v77TV4HKME",
        "outputId": "58fe31d8-8862-4f6c-a821-88a845c203da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "ziHdrhECHZlZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_YLHiV-HeEN",
        "outputId": "06021e66-2ea7-4e27-b904-63444cbe5d0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8966101694915254\n",
            "Precision: 0.8998235533328679\n",
            "Recall: 0.8966101694915254\n",
            "F1 Score: 0.894781519791972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function for ensemble prediction\n",
        "def predict_plant_ensemble(image_path):\n",
        "    img = image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    # Predict with each model\n",
        "    prediction_201 = loaded_model_201.predict(img_array)\n",
        "    prediction_169 = loaded_model_169.predict(img_array)\n",
        "    prediction_121 = loaded_model_121.predict(img_array)\n",
        "\n",
        "    # Combine predictions (e.g., simple averaging)\n",
        "    ensemble_prediction = (prediction_201 + prediction_169 + prediction_121) / 3.0\n",
        "\n",
        "    # Get the predicted class index\n",
        "    class_index = np.argmax(ensemble_prediction)\n",
        "\n",
        "    # Map the class index to plant name\n",
        "    plant_name = class_mapping.get(class_index, 'Unknown Plant')\n",
        "\n",
        "    # Get the confidence level\n",
        "    confidence = ensemble_prediction[0, class_index]\n",
        "\n",
        "    return plant_name, confidence\n",
        "\n"
      ],
      "metadata": {
        "id": "ogmo3pLBH5z5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "image_path = '/content/test4.jpg'\n",
        "predicted_plant, confidence = predict_plant_ensemble(image_path)\n",
        "print(f\"Predicted plant: {predicted_plant}\")\n",
        "print(f\"Confidence level: {confidence * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQgJVnQ3H70R",
        "outputId": "6ef1e6e0-6ad2-4030-9de8-9b8e842384d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 143ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "Predicted plant: Hibiscus\n",
            "Confidence level: 88.18%\n"
          ]
        }
      ]
    }
  ]
}