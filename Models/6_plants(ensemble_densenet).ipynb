{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Sub6Fmo5LuE","executionInfo":{"status":"ok","timestamp":1714303348696,"user_tz":-330,"elapsed":9833,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"outputId":"da693c78-aa96-462e-9e4e-6f61eed3b02e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,  LSTM, Reshape,  TimeDistributed\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","!pip install opendatasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KpkOfbW5dv1","executionInfo":{"status":"ok","timestamp":1714304025953,"user_tz":-330,"elapsed":558456,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce36221e-e03d-4103-eda9-63111ee79979"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: harsh25k\n","Your Kaggle Key: ··········\n","Downloading indian-medicinal-leaves-dataset.zip to ./indian-medicinal-leaves-dataset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.00G/9.00G [07:43<00:00, 20.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["import opendatasets as od\n","od.download(\"https://www.kaggle.com/datasets/aryashah2k/indian-medicinal-leaves-dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYcTFm7FOE4t"},"outputs":[],"source":["# Define parameters\n","input_shape = (150, 150, 3)  # Adjust the image size as needed\n","batch_size = 32\n","epochs = 20\n","num_classes = 40  # Number of different plant classes\n","data_dir = \"/content/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal plant dataset\"  # Replace with the path to your dataset folder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cadYph4S5jZ3"},"outputs":[],"source":["# Create a mapping between class indices and plant names\n","class_mapping = {\n","    0: 'Aloevera',\n","    1: 'Amla',\n","    2: 'Amruta Balli',\n","    3: 'Arali',\n","    4: 'Ashoka',\n","    5: 'Ashwagandha',\n","    6: 'Avacado',\n","    7: 'Bamboo',\n","    8: 'Basale',\n","    9: 'Betel',\n","    10: 'Betel_Nut',\n","    11: 'Brahmi',\n","    12: 'Castor',\n","    13: 'Curry Leaf',\n","    14: 'Doddapatre',\n","    15: 'Ekka',\n","    16: 'Ganike',\n","    17: 'Gauva',\n","    18: 'Geranium',\n","    19: 'Henna',\n","    20: 'Hibiscus',\n","    21: 'Honge',\n","    22: 'Insulin',\n","    23: 'Jasmine',\n","    24: 'Lemon',\n","    25: 'Lemon_grass',\n","    26: 'Mango',\n","    27: 'Mint',\n","    28: 'Nagadali',\n","    29: 'Neem',\n","    30: 'Nithyapushpa',\n","    31: 'Nooni',\n","    32: 'Pappaya',\n","    33: 'Pepper',\n","    34: 'Pomegranate',\n","    35: 'Raktachandini',\n","    36: 'Rose',\n","    37: 'Sapota',\n","    38: 'Tulasi',\n","    39: 'Wood_sorel',\n","    # Add mappings for all 40 classes here\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIlCP2o75pQ6"},"outputs":[],"source":["# Data preprocessing and augmentation\n","datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,     # Normalize pixel values\n","    rotation_range=20,      # Randomly rotate images\n","    width_shift_range=0.2,  # Randomly shift images horizontally\n","    height_shift_range=0.2, # Randomly shift images vertically\n","    shear_range=0.2,        # Shear intensity\n","    zoom_range=0.2,         # Randomly zoom in on images\n","    horizontal_flip=True,   # Randomly flip images horizontally\n","    fill_mode='nearest',    # Fill missing pixels with the nearest value\n","    validation_split=0.2     # 20% of data will be used for validation\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ka87i8dZNTsu","executionInfo":{"status":"ok","timestamp":1714304025954,"user_tz":-330,"elapsed":7,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6c0e074-83a8-4564-a269-b1c9098b5e0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4765 images belonging to 40 classes.\n"]}],"source":["# Load and augment training data (80%)\n","train_generator = datagen.flow_from_directory(\n","    data_dir,                 # Root directory containing 40 subfolders\n","    target_size=input_shape[:2],   # Resize images to match input_shape\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical classification\n","    shuffle=True,             # Shuffle the data for training\n","    subset='training'         # Specify training data subset\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ-OFIlnJCdK","executionInfo":{"status":"ok","timestamp":1714304025954,"user_tz":-330,"elapsed":6,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"351ca4b0-aec8-43f7-fe33-48f1b55bb012"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1180 images belonging to 40 classes.\n"]}],"source":["# Load and augment validation data (20%)\n","validation_generator = datagen.flow_from_directory(\n","    data_dir,                 # Root directory containing 40 subfolders\n","    target_size=input_shape[:2],  # Resize images to match input_shape\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical classification\n","    shuffle=False,            # Do not shuffle for validation\n","    subset='validation'       # Specify validation data subset\n",")\n"]},{"cell_type":"code","source":["# Load and augment training data (80%) for DenseNet121\n","train_generator_d121 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet121\n",")\n","\n","# Load and augment validation data (20%) for DenseNet121\n","validation_generator_d121 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet121\n",")\n","\n","# Repeat the same process for DenseNet169 and DenseNet201\n","# Load and augment training data (80%) for DenseNet169\n","train_generator_d169 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet169\n",")\n","\n","# Load and augment validation data (20%) for DenseNet169\n","validation_generator_d169 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet169\n",")\n","\n","# Load and augment training data (80%) for DenseNet201\n","train_generator_d201 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet201\n",")\n","\n","# Load and augment validation data (20%) for DenseNet201\n","validation_generator_d201 = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to DenseNet201\n",")"],"metadata":{"id":"d4pSYlrcDjtC","executionInfo":{"status":"ok","timestamp":1714304026566,"user_tz":-330,"elapsed":617,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6244106e-1743-415b-8dd2-9e819ad3be91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n","Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n","Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Concatenate, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# Define input shape\n","# input_shape = (224, 224, 3)  # Assuming input images are 224x224 RGB images\n","num_classes = 40  # Define the number of classes in your dataset\n","\n","# Load DenseNet121\n","input_d121 = Input(shape=input_shape)\n","base_model_d121 = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_d121)\n","for layer in base_model_d121.layers:\n","    layer._name = layer.name + '_d121'  # Appending \"_d121\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_d121 = GlobalAveragePooling2D()(base_model_d121.output)\n","\n","# Load DenseNet169\n","input_d169 = Input(shape=input_shape)\n","base_model_d169 = DenseNet169(weights='imagenet', include_top=False, input_tensor=input_d169)\n","for layer in base_model_d169.layers:\n","    layer._name = layer.name + '_d169'  # Appending \"_d169\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_d169 = GlobalAveragePooling2D()(base_model_d169.output)\n","\n","# Load DenseNet201\n","input_d201 = Input(shape=input_shape)\n","base_model_d201 = DenseNet201(weights='imagenet', include_top=False, input_tensor=input_d201)\n","for layer in base_model_d201.layers:\n","    layer._name = layer.name + '_d201'  # Appending \"_d201\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_d201 = GlobalAveragePooling2D()(base_model_d201.output)\n","\n","# Concatenate outputs from all models\n","merged = Concatenate()([output_d121, output_d169, output_d201])\n","\n","# Add dense layers for classification\n","x = Dense(128, activation='relu')(merged)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","\n","# Create ensemble model\n","ensemble_model = Model(inputs=[input_d121, input_d169, input_d201], outputs=predictions)\n","\n","# Compile the ensemble model\n","ensemble_model.compile(optimizer=Adam(learning_rate=0.0001),  # Adjust the learning rate if needed\n","                       loss='categorical_crossentropy',\n","                       metrics=['accuracy'])\n","\n","\n","import numpy as np\n","from tensorflow.keras.utils import Sequence\n","\n","class MultiDataGenerator(Sequence):\n","    def __init__(self, generators):\n","        self.generators = generators\n","\n","    def __len__(self):\n","        return len(self.generators[0])\n","\n","    def __getitem__(self, idx):\n","        batch_x = [generator[idx][0] for generator in self.generators]\n","        batch_y = self.generators[0][idx][1]  # Assuming the first generator provides both input and target\n","        return batch_x, batch_y\n","\n","# Create a multi-data generator for training\n","train_multi_generator = MultiDataGenerator([train_generator_d121, train_generator_d169, train_generator_d201])\n","\n","# Create a multi-data generator for validation\n","validation_multi_generator = MultiDataGenerator([validation_generator_d121, validation_generator_d169, validation_generator_d201])\n","\n","# Train the model using the multi-data generator\n","history = ensemble_model.fit(\n","    train_multi_generator,\n","    epochs=20,\n","    validation_data=validation_multi_generator\n",")\n","\n","\n","\n","# Train the model with validation data\n","# history = ensemble_model.fit(\n","#     x=[train_generator_d121, train_generator_d169, train_generator_d201],  # Provide input data generators for each DenseNet model\n","#     epochs=20,\n","#     validation_data=([validation_generator_d121, validation_generator_d169, validation_generator_d201]),  # Use validation data generators\n","# )\n","\n","\n","\n"],"metadata":{"id":"ABMPI55dIXm7","executionInfo":{"status":"ok","timestamp":1714314147053,"user_tz":-330,"elapsed":3740608,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5440ec50-0ea1-4d14-dfe2-7b28e394da7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","149/149 [==============================] - 220s 1s/step - loss: 3.6971 - accuracy: 0.0575 - val_loss: 3.5500 - val_accuracy: 0.0712\n","Epoch 2/20\n","149/149 [==============================] - 184s 1s/step - loss: 3.2899 - accuracy: 0.1463 - val_loss: 3.1565 - val_accuracy: 0.1746\n","Epoch 3/20\n","149/149 [==============================] - 185s 1s/step - loss: 2.8257 - accuracy: 0.2615 - val_loss: 2.7634 - val_accuracy: 0.2653\n","Epoch 4/20\n","149/149 [==============================] - 188s 1s/step - loss: 2.4225 - accuracy: 0.3765 - val_loss: 2.4043 - val_accuracy: 0.3720\n","Epoch 5/20\n","149/149 [==============================] - 182s 1s/step - loss: 2.0834 - accuracy: 0.4636 - val_loss: 2.2017 - val_accuracy: 0.4398\n","Epoch 6/20\n","149/149 [==============================] - 182s 1s/step - loss: 1.8515 - accuracy: 0.5196 - val_loss: 2.0243 - val_accuracy: 0.4644\n","Epoch 7/20\n","149/149 [==============================] - 186s 1s/step - loss: 1.6693 - accuracy: 0.5834 - val_loss: 1.8734 - val_accuracy: 0.4890\n","Epoch 8/20\n","149/149 [==============================] - 185s 1s/step - loss: 1.5047 - accuracy: 0.6243 - val_loss: 1.7577 - val_accuracy: 0.5390\n","Epoch 9/20\n","149/149 [==============================] - 181s 1s/step - loss: 1.3656 - accuracy: 0.6619 - val_loss: 1.6471 - val_accuracy: 0.5576\n","Epoch 10/20\n","149/149 [==============================] - 181s 1s/step - loss: 1.2718 - accuracy: 0.6762 - val_loss: 1.6104 - val_accuracy: 0.5551\n","Epoch 11/20\n","149/149 [==============================] - 179s 1s/step - loss: 1.1696 - accuracy: 0.7152 - val_loss: 1.5060 - val_accuracy: 0.5907\n","Epoch 12/20\n","149/149 [==============================] - 184s 1s/step - loss: 1.0852 - accuracy: 0.7251 - val_loss: 1.4433 - val_accuracy: 0.5941\n","Epoch 13/20\n","149/149 [==============================] - 178s 1s/step - loss: 1.0267 - accuracy: 0.7442 - val_loss: 1.4087 - val_accuracy: 0.6144\n","Epoch 14/20\n","149/149 [==============================] - 178s 1s/step - loss: 0.9533 - accuracy: 0.7618 - val_loss: 1.3802 - val_accuracy: 0.6203\n","Epoch 15/20\n","149/149 [==============================] - 178s 1s/step - loss: 0.8959 - accuracy: 0.7782 - val_loss: 1.3387 - val_accuracy: 0.6364\n","Epoch 16/20\n","149/149 [==============================] - 177s 1s/step - loss: 0.8607 - accuracy: 0.7813 - val_loss: 1.3089 - val_accuracy: 0.6331\n","Epoch 17/20\n","149/149 [==============================] - 178s 1s/step - loss: 0.8026 - accuracy: 0.8082 - val_loss: 1.3204 - val_accuracy: 0.6288\n","Epoch 18/20\n","149/149 [==============================] - 176s 1s/step - loss: 0.7736 - accuracy: 0.8136 - val_loss: 1.2331 - val_accuracy: 0.6449\n","Epoch 19/20\n","149/149 [==============================] - 178s 1s/step - loss: 0.7410 - accuracy: 0.8145 - val_loss: 1.2165 - val_accuracy: 0.6542\n","Epoch 20/20\n","149/149 [==============================] - 177s 1s/step - loss: 0.6981 - accuracy: 0.8254 - val_loss: 1.1701 - val_accuracy: 0.6695\n"]}]},{"cell_type":"code","source":["\n","# Reset the validation generators\n","validation_generator_d121.reset()\n","validation_generator_d169.reset()\n","validation_generator_d201.reset()\n"],"metadata":{"id":"V9XdQuOL1Uwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Get the number of steps for validation data\n","validation_steps = len(validation_generator_d121)\n","\n","# Initialize empty lists to store predictions and true labels\n","y_pred_probs_list = []\n","y_true_list = []\n","\n","# Loop through validation generator batches to get predictions\n","for _ in range(validation_steps):\n","    # Get batches of validation data for each DenseNet model\n","    batch_x_d121, batch_y_d121 = validation_generator_d121.next()\n","    batch_x_d169, batch_y_d169 = validation_generator_d169.next()\n","    batch_x_d201, batch_y_d201 = validation_generator_d201.next()\n","\n","    # Make predictions using the ensemble model for each batch\n","    y_pred_probs_batch = ensemble_model.predict([batch_x_d121, batch_x_d169, batch_x_d201])\n","\n","    # Append predictions and true labels to the lists\n","    y_pred_probs_list.append(y_pred_probs_batch)\n","    y_true_list.append(batch_y_d121)  # Assuming all generators have the same true labels\n","\n","# Concatenate predictions and true labels from all batches\n","y_pred_probs = np.concatenate(y_pred_probs_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# Convert predicted probabilities to class labels\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","\n","\n","# Convert one-hot encoded true labels to class labels\n","y_true_class = np.argmax(y_true, axis=1)\n","\n","# Calculate evaluation metrics using class labels\n","accuracy = accuracy_score(y_true_class, y_pred)\n","precision = precision_score(y_true_class, y_pred, average='weighted')\n","recall = recall_score(y_true_class, y_pred, average='weighted')\n","f1 = f1_score(y_true_class, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1 Score: {f1}')\n","\n","# Display classification report and confusion matrix\n","class_names = list(class_mapping.values())\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true_class, y_pred, target_names=class_names))\n","\n","print(\"\\nConfusion Matrix:\")\n","conf_matrix = confusion_matrix(y_true_class, y_pred)\n","print(conf_matrix)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txPelTRV1ZWW","executionInfo":{"status":"ok","timestamp":1714310188226,"user_tz":-330,"elapsed":38013,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"outputId":"05d1dc19-9f41-4ebe-a099-4720d6af9db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 263ms/step\n","1/1 [==============================] - 0s 193ms/step\n","1/1 [==============================] - 0s 239ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 159ms/step\n","1/1 [==============================] - 0s 178ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 187ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 184ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 187ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 174ms/step\n","1/1 [==============================] - 0s 186ms/step\n","1/1 [==============================] - 0s 185ms/step\n","1/1 [==============================] - 0s 186ms/step\n","1/1 [==============================] - 0s 190ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 185ms/step\n","1/1 [==============================] - 0s 190ms/step\n","1/1 [==============================] - 0s 172ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 212ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 162ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 184ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 170ms/step\n","Accuracy: 0.07288135593220339\n","Precision: 0.06858317226927753\n","Recall: 0.07288135593220339\n","F1 Score: 0.06070115846144688\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","     Aloevera       0.16      0.47      0.24        32\n","         Amla       0.07      0.03      0.05        29\n"," Amruta Balli       0.00      0.00      0.00        29\n","        Arali       0.32      0.38      0.35        29\n","       Ashoka       0.00      0.00      0.00        29\n","  Ashwagandha       0.00      0.00      0.00        29\n","      Avacado       0.03      0.03      0.03        29\n","       Bamboo       0.06      0.03      0.04        29\n","       Basale       0.15      0.07      0.10        29\n","        Betel       0.14      0.17      0.15        30\n","    Betel_Nut       0.07      0.07      0.07        29\n","       Brahmi       0.00      0.00      0.00        29\n","       Castor       0.09      0.03      0.05        32\n","   Curry Leaf       0.14      0.10      0.12        29\n","   Doddapatre       0.02      0.07      0.03        29\n","         Ekka       0.00      0.00      0.00        29\n","       Ganike       0.00      0.00      0.00        23\n","        Gauva       0.31      0.17      0.22        29\n","     Geranium       0.08      0.21      0.12        29\n","        Henna       0.04      0.10      0.06        30\n","     Hibiscus       0.00      0.00      0.00        33\n","        Honge       0.05      0.10      0.07        29\n","      Insulin       0.00      0.00      0.00        29\n","      Jasmine       0.07      0.11      0.08        37\n","        Lemon       0.20      0.03      0.06        29\n","  Lemon_grass       0.00      0.00      0.00        29\n","        Mango       0.05      0.17      0.07        29\n","         Mint       0.07      0.20      0.11        30\n","     Nagadali       0.00      0.00      0.00        30\n","         Neem       0.00      0.00      0.00        29\n"," Nithyapushpa       0.00      0.00      0.00        29\n","        Nooni       0.08      0.07      0.07        29\n","      Pappaya       0.04      0.03      0.04        29\n","       Pepper       0.11      0.03      0.05        29\n","  Pomegranate       0.00      0.00      0.00        29\n","Raktachandini       0.09      0.03      0.05        29\n","         Rose       0.03      0.03      0.03        33\n","       Sapota       0.20      0.07      0.10        29\n","       Tulasi       0.06      0.03      0.04        29\n","   Wood_sorel       0.00      0.00      0.00        29\n","\n","     accuracy                           0.07      1180\n","    macro avg       0.07      0.07      0.06      1180\n"," weighted avg       0.07      0.07      0.06      1180\n","\n","\n","Confusion Matrix:\n","[[15  0  0 ...  0  1  1]\n"," [ 3  1  0 ...  0  1  1]\n"," [ 3  0  0 ...  0  1  2]\n"," ...\n"," [ 1  0  0 ...  2  0  0]\n"," [ 7  1  0 ...  0  1  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]}]},{"cell_type":"code","source":["\n","# Save the trained model\n","ensemble_model.save('ensemble_densenets.h5')"],"metadata":{"id":"_gbEcwq51bww"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tw4IFqNpWqL0"},"outputs":[],"source":["ensemble_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asMraqylAot8"},"outputs":[],"source":["# # Evaluate the model on the validation set\n","# validation_steps = len(validation_generator)\n","# validation_generator.reset()\n","# y_true = validation_generator.classes\n","# y_pred_probs = ensemble_model.predict(validation_generator, steps=validation_steps)\n","# y_pred = np.argmax(y_pred_probs, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d7GP9ToqSsr"},"outputs":[],"source":["# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# # Calculate evaluation metrics\n","# accuracy = accuracy_score(y_true, y_pred)\n","# precision = precision_score(y_true, y_pred, average='weighted')\n","# recall = recall_score(y_true, y_pred, average='weighted')\n","# f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","# print(f'Accuracy: {accuracy}')\n","# print(f'Precision: {precision}')\n","# print(f'Recall: {recall}')\n","# print(f'F1 Score: {f1}')\n","\n","# # Display classification report and confusion matrix\n","# class_names = list(class_mapping.values())\n","# print(\"\\nClassification Report:\")\n","# print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","# print(\"\\nConfusion Matrix:\")\n","# conf_matrix = confusion_matrix(y_true, y_pred)\n","# print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psO9iGjcSU1L"},"outputs":[],"source":["# Save the trained model\n","# model.save('plant_classification_model_transfer.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dR8p9hQBGfs9"},"outputs":[],"source":["# Load the model for inference\n","# loaded_model = keras.models.load_model('plant_classification_model_transfer.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fpSc0MRGi-4"},"outputs":[],"source":["# Example code for prediction on a new image\n","def predict_plant(image_path):\n","    img = image.load_img(image_path, target_size=input_shape[:2])\n","    img = image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img /= 255.0\n","\n","    prediction = loaded_model.predict(img)\n","    class_index = np.argmax(prediction)\n","    plant_name = class_mapping.get(class_index, 'Unknown Plant')\n","    confidence = np.max(prediction)\n","\n","    return plant_name, confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pcfmXz6GlzL"},"outputs":[],"source":["# Example usage:\n","image_path = '/content/aloe.jpg'\n","predicted_plant, confidence = predict_plant(image_path)\n","print(f\"Predicted plant: {predicted_plant}\")\n","print(f\"Confidence level: {confidence * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qS-NCgUL43OM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}