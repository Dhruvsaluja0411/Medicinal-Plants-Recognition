{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Sub6Fmo5LuE","executionInfo":{"status":"ok","timestamp":1714310911957,"user_tz":-330,"elapsed":9336,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}},"outputId":"bdbcdecb-27de-4ad4-b6d5-9753138d1771"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from tensorflow.keras.applications import DenseNet121\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,  LSTM, Reshape,  TimeDistributed\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","!pip install opendatasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KpkOfbW5dv1","executionInfo":{"status":"ok","timestamp":1714310964658,"user_tz":-330,"elapsed":29754,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"598ecde8-7921-4751-be68-925c36d4d934"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: dhruvsaluja\n","Your Kaggle Key: ··········\n","Downloading indian-medicinal-plants.zip to ./indian-medicinal-plants\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 253M/253M [00:02<00:00, 99.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["import opendatasets as od\n","od.download(\"https://www.kaggle.com/datasets/dhruvsaluja/indian-medicinal-plants\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYcTFm7FOE4t"},"outputs":[],"source":["# Define parameters\n","input_shape = (224, 224, 3)  # Adjust the image size as needed\n","batch_size = 32\n","epochs = 20\n","num_classes = 40  # Number of different plant classes\n","data_dir = \"/content/indian-medicinal-plants/Indian Medicinal Plant Image Datasets/Medicinal plant dataset\"  # Replace with the path to your dataset folder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cadYph4S5jZ3"},"outputs":[],"source":["# Create a mapping between class indices and plant names\n","class_mapping = {\n","    0: 'Aloevera',\n","    1: 'Amla',\n","    2: 'Amruta Balli',\n","    3: 'Arali',\n","    4: 'Ashoka',\n","    5: 'Ashwagandha',\n","    6: 'Avacado',\n","    7: 'Bamboo',\n","    8: 'Basale',\n","    9: 'Betel',\n","    10: 'Betel_Nut',\n","    11: 'Brahmi',\n","    12: 'Castor',\n","    13: 'Curry Leaf',\n","    14: 'Doddapatre',\n","    15: 'Ekka',\n","    16: 'Ganike',\n","    17: 'Gauva',\n","    18: 'Geranium',\n","    19: 'Henna',\n","    20: 'Hibiscus',\n","    21: 'Honge',\n","    22: 'Insulin',\n","    23: 'Jasmine',\n","    24: 'Lemon',\n","    25: 'Lemon_grass',\n","    26: 'Mango',\n","    27: 'Mint',\n","    28: 'Nagadali',\n","    29: 'Neem',\n","    30: 'Nithyapushpa',\n","    31: 'Nooni',\n","    32: 'Pappaya',\n","    33: 'Pepper',\n","    34: 'Pomegranate',\n","    35: 'Raktachandini',\n","    36: 'Rose',\n","    37: 'Sapota',\n","    38: 'Tulasi',\n","    39: 'Wood_sorel',\n","    # Add mappings for all 40 classes here\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIlCP2o75pQ6"},"outputs":[],"source":["# Data preprocessing and augmentation\n","datagen = ImageDataGenerator(\n","    rescale=1.0 / 255.0,     # Normalize pixel values\n","    rotation_range=20,      # Randomly rotate images\n","    width_shift_range=0.2,  # Randomly shift images horizontally\n","    height_shift_range=0.2, # Randomly shift images vertically\n","    shear_range=0.2,        # Shear intensity\n","    zoom_range=0.2,         # Randomly zoom in on images\n","    horizontal_flip=True,   # Randomly flip images horizontally\n","    fill_mode='nearest',    # Fill missing pixels with the nearest value\n","    validation_split=0.2     # 20% of data will be used for validation\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ka87i8dZNTsu","executionInfo":{"status":"ok","timestamp":1714311074203,"user_tz":-330,"elapsed":412,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4595ac0-c1d9-4827-d6da-3102fa3a649b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4765 images belonging to 40 classes.\n"]}],"source":["# Load and augment training data (80%)\n","train_generator = datagen.flow_from_directory(\n","    data_dir,                 # Root directory containing 40 subfolders\n","    target_size=input_shape[:2],   # Resize images to match input_shape\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical classification\n","    shuffle=True,             # Shuffle the data for training\n","    subset='training'         # Specify training data subset\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ-OFIlnJCdK","executionInfo":{"status":"ok","timestamp":1714311079658,"user_tz":-330,"elapsed":436,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"78108b4e-77b1-47be-82eb-580e0a886ceb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1180 images belonging to 40 classes.\n"]}],"source":["# Load and augment validation data (20%)\n","validation_generator = datagen.flow_from_directory(\n","    data_dir,                 # Root directory containing 40 subfolders\n","    target_size=input_shape[:2],  # Resize images to match input_shape\n","    batch_size=batch_size,\n","    class_mode='categorical',  # Categorical classification\n","    shuffle=False,            # Do not shuffle for validation\n","    subset='validation'       # Specify validation data subset\n",")\n"]},{"cell_type":"code","source":["# Load and augment training data (80%) for MobileNetV2\n","train_generator_mobilenet = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to MobileNetV2\n",")\n","\n","# Load and augment validation data (20%) for MobileNetV2\n","validation_generator_mobilenet = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to MobileNetV2\n",")\n","\n","# Repeat the same process for VGG16\n","# Load and augment training data (80%) for VGG16\n","train_generator_vgg = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to VGG16\n",")\n","\n","# Load and augment validation data (20%) for VGG16\n","validation_generator_vgg = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to VGG16\n",")\n","\n","# Repeat the same process for ResNet18\n","# Load and augment training data (80%) for ResNet18\n","train_generator_resnet = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to ResNet18\n",")\n","\n","# Load and augment validation data (20%) for ResNet18\n","validation_generator_resnet = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=input_shape[:2],\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False,\n","    subset='validation',\n","    # classes=['class1', 'class2', ..., 'classN']  # List of class subfolders specific to ResNet18\n",")\n"],"metadata":{"id":"d4pSYlrcDjtC","executionInfo":{"status":"ok","timestamp":1714311450672,"user_tz":-330,"elapsed":706,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"04f2c001-505b-4d61-b4b5-02926cd58052"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n","Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n","Found 4765 images belonging to 40 classes.\n","Found 1180 images belonging to 40 classes.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.utils import Sequence\n","\n","class MultiDataGenerator(Sequence):\n","    def __init__(self, generators):\n","        self.generators = generators\n","\n","    def __len__(self):\n","        return len(self.generators[0])\n","\n","    def __getitem__(self, idx):\n","        batch_x = [generator[idx][0] for generator in self.generators]\n","        batch_y = self.generators[0][idx][1]  # Assuming the first generator provides both input and target\n","        return batch_x, batch_y\n"],"metadata":{"id":"SBZ4a8JF735U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Concatenate, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import MobileNetV2, VGG16, ResNet50  # Import ResNet50 instead of ResNet18\n","\n","from tensorflow.keras.metrics import Accuracy\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# Define input shape\n","input_shape = (224, 224, 3)  # Assuming input images are 224x224 RGB images\n","num_classes = 40  # Define the number of classes in your dataset\n","\n","# Load MobileNetV2\n","input_mobilenet = Input(shape=input_shape)\n","base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_mobilenet)\n","for layer in base_model_mobilenet.layers:\n","    layer._name = layer.name + '_mobilenet'  # Append \"_mobilenet\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_mobilenet = GlobalAveragePooling2D()(base_model_mobilenet.output)\n","\n","# Load VGG16\n","input_vgg = Input(shape=input_shape)\n","base_model_vgg = VGG16(weights='imagenet', include_top=False, input_tensor=input_vgg)\n","for layer in base_model_vgg.layers:\n","    layer._name = layer.name + '_vgg'  # Append \"_vgg\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_vgg = GlobalAveragePooling2D()(base_model_vgg.output)\n","\n","# Load ResNet18\n","input_resnet = Input(shape=input_shape)\n","base_model_resnet = ResNet50(weights='imagenet', include_top=False, input_tensor=input_resnet)\n","for layer in base_model_resnet.layers:\n","    layer._name = layer.name + '_resnet'  # Append \"_resnet\" to each layer's name to make them unique\n","    layer.trainable = False\n","output_resnet = GlobalAveragePooling2D()(base_model_resnet.output)\n","\n","# Concatenate outputs from all models\n","merged = Concatenate()([output_mobilenet, output_vgg, output_resnet])\n","\n","# Add dense layers for classification\n","x = Dense(128, activation='relu')(merged)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","\n","# Create ensemble model\n","ensemble_model = Model(inputs=[input_mobilenet, input_vgg, input_resnet], outputs=predictions)\n","\n","# Compile the ensemble model\n","ensemble_model.compile(optimizer=Adam(learning_rate=0.0001),  # Adjust the learning rate if needed\n","                       loss='categorical_crossentropy',\n","                       metrics=['accuracy', Accuracy()])\n","\n","# Assuming you have defined train_generator_mobilenet, train_generator_vgg, train_generator_resnet,\n","# validation_generator_mobilenet, validation_generator_vgg, and validation_generator_resnet earlier\n","\n","# Create a multi-data generator for training\n","train_multi_generator = MultiDataGenerator([train_generator_mobilenet, train_generator_vgg, train_generator_resnet])\n","\n","# Create a multi-data generator for validation\n","validation_multi_generator = MultiDataGenerator([validation_generator_mobilenet, validation_generator_vgg, validation_generator_resnet])\n","\n","# Train the model using the multi-data generator\n","history = ensemble_model.fit(\n","    train_multi_generator,\n","    epochs=1,\n","    validation_data=validation_multi_generator\n",")\n"],"metadata":{"id":"ABMPI55dIXm7","colab":{"base_uri":"https://localhost:8080/","height":723},"outputId":"3524b6c6-d48c-4af0-8510-ab134cb2ef8f","executionInfo":{"status":"error","timestamp":1714311642540,"user_tz":-330,"elapsed":8062,"user":{"displayName":"Harsh Kukreja","userId":"00597259600799973024"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 592, in update_state\n        self.build(y_pred, y_true)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 521, in build\n        self._set_metric_names()\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 547, in _set_metric_names\n        raise ValueError(\n\n    ValueError: Found two metrics with the same name: accuracy. All the metrics added to the model need to have unique names.\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-2ba0a43f5c53>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Train the model using the multi-data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m history = ensemble_model.fit(\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mtrain_multi_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 592, in update_state\n        self.build(y_pred, y_true)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 521, in build\n        self._set_metric_names()\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 547, in _set_metric_names\n        raise ValueError(\n\n    ValueError: Found two metrics with the same name: accuracy. All the metrics added to the model need to have unique names.\n"]}]},{"cell_type":"code","source":["\n","# Reset the validation generators\n","validation_generator_d121.reset()\n","validation_generator_d169.reset()\n","validation_generator_d201.reset()\n"],"metadata":{"id":"V9XdQuOL1Uwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Get the number of steps for validation data\n","validation_steps = len(validation_generator_d121)\n","\n","# Initialize empty lists to store predictions and true labels\n","y_pred_probs_list = []\n","y_true_list = []\n","\n","# Loop through validation generator batches to get predictions\n","for _ in range(validation_steps):\n","    # Get batches of validation data for each DenseNet model\n","    batch_x_d121, batch_y_d121 = validation_generator_d121.next()\n","    batch_x_d169, batch_y_d169 = validation_generator_d169.next()\n","    batch_x_d201, batch_y_d201 = validation_generator_d201.next()\n","\n","    # Make predictions using the ensemble model for each batch\n","    y_pred_probs_batch = ensemble_model.predict([batch_x_d121, batch_x_d169, batch_x_d201])\n","\n","    # Append predictions and true labels to the lists\n","    y_pred_probs_list.append(y_pred_probs_batch)\n","    y_true_list.append(batch_y_d121)  # Assuming all generators have the same true labels\n","\n","# Concatenate predictions and true labels from all batches\n","y_pred_probs = np.concatenate(y_pred_probs_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# Convert predicted probabilities to class labels\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","\n","\n","# Convert one-hot encoded true labels to class labels\n","y_true_class = np.argmax(y_true, axis=1)\n","\n","# Calculate evaluation metrics using class labels\n","accuracy = accuracy_score(y_true_class, y_pred)\n","precision = precision_score(y_true_class, y_pred, average='weighted')\n","recall = recall_score(y_true_class, y_pred, average='weighted')\n","f1 = f1_score(y_true_class, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1 Score: {f1}')\n","\n","# Display classification report and confusion matrix\n","class_names = list(class_mapping.values())\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true_class, y_pred, target_names=class_names))\n","\n","print(\"\\nConfusion Matrix:\")\n","conf_matrix = confusion_matrix(y_true_class, y_pred)\n","print(conf_matrix)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txPelTRV1ZWW","executionInfo":{"status":"ok","timestamp":1714310188226,"user_tz":-330,"elapsed":38013,"user":{"displayName":"John Doe","userId":"01177160756613860822"}},"outputId":"05d1dc19-9f41-4ebe-a099-4720d6af9db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 263ms/step\n","1/1 [==============================] - 0s 193ms/step\n","1/1 [==============================] - 0s 239ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 159ms/step\n","1/1 [==============================] - 0s 178ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 187ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 184ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 187ms/step\n","1/1 [==============================] - 0s 205ms/step\n","1/1 [==============================] - 0s 174ms/step\n","1/1 [==============================] - 0s 186ms/step\n","1/1 [==============================] - 0s 185ms/step\n","1/1 [==============================] - 0s 186ms/step\n","1/1 [==============================] - 0s 190ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 185ms/step\n","1/1 [==============================] - 0s 190ms/step\n","1/1 [==============================] - 0s 172ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 212ms/step\n","1/1 [==============================] - 0s 206ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 162ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 181ms/step\n","1/1 [==============================] - 0s 180ms/step\n","1/1 [==============================] - 0s 184ms/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 183ms/step\n","1/1 [==============================] - 0s 170ms/step\n","Accuracy: 0.07288135593220339\n","Precision: 0.06858317226927753\n","Recall: 0.07288135593220339\n","F1 Score: 0.06070115846144688\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","     Aloevera       0.16      0.47      0.24        32\n","         Amla       0.07      0.03      0.05        29\n"," Amruta Balli       0.00      0.00      0.00        29\n","        Arali       0.32      0.38      0.35        29\n","       Ashoka       0.00      0.00      0.00        29\n","  Ashwagandha       0.00      0.00      0.00        29\n","      Avacado       0.03      0.03      0.03        29\n","       Bamboo       0.06      0.03      0.04        29\n","       Basale       0.15      0.07      0.10        29\n","        Betel       0.14      0.17      0.15        30\n","    Betel_Nut       0.07      0.07      0.07        29\n","       Brahmi       0.00      0.00      0.00        29\n","       Castor       0.09      0.03      0.05        32\n","   Curry Leaf       0.14      0.10      0.12        29\n","   Doddapatre       0.02      0.07      0.03        29\n","         Ekka       0.00      0.00      0.00        29\n","       Ganike       0.00      0.00      0.00        23\n","        Gauva       0.31      0.17      0.22        29\n","     Geranium       0.08      0.21      0.12        29\n","        Henna       0.04      0.10      0.06        30\n","     Hibiscus       0.00      0.00      0.00        33\n","        Honge       0.05      0.10      0.07        29\n","      Insulin       0.00      0.00      0.00        29\n","      Jasmine       0.07      0.11      0.08        37\n","        Lemon       0.20      0.03      0.06        29\n","  Lemon_grass       0.00      0.00      0.00        29\n","        Mango       0.05      0.17      0.07        29\n","         Mint       0.07      0.20      0.11        30\n","     Nagadali       0.00      0.00      0.00        30\n","         Neem       0.00      0.00      0.00        29\n"," Nithyapushpa       0.00      0.00      0.00        29\n","        Nooni       0.08      0.07      0.07        29\n","      Pappaya       0.04      0.03      0.04        29\n","       Pepper       0.11      0.03      0.05        29\n","  Pomegranate       0.00      0.00      0.00        29\n","Raktachandini       0.09      0.03      0.05        29\n","         Rose       0.03      0.03      0.03        33\n","       Sapota       0.20      0.07      0.10        29\n","       Tulasi       0.06      0.03      0.04        29\n","   Wood_sorel       0.00      0.00      0.00        29\n","\n","     accuracy                           0.07      1180\n","    macro avg       0.07      0.07      0.06      1180\n"," weighted avg       0.07      0.07      0.06      1180\n","\n","\n","Confusion Matrix:\n","[[15  0  0 ...  0  1  1]\n"," [ 3  1  0 ...  0  1  1]\n"," [ 3  0  0 ...  0  1  2]\n"," ...\n"," [ 1  0  0 ...  2  0  0]\n"," [ 7  1  0 ...  0  1  0]\n"," [ 0  0  0 ...  0  0  0]]\n"]}]},{"cell_type":"code","source":["\n","# Save the trained model\n","ensemble_model.save('ensemble_densenets.h5')"],"metadata":{"id":"_gbEcwq51bww"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tw4IFqNpWqL0"},"outputs":[],"source":["ensemble_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asMraqylAot8"},"outputs":[],"source":["# # Evaluate the model on the validation set\n","# validation_steps = len(validation_generator)\n","# validation_generator.reset()\n","# y_true = validation_generator.classes\n","# y_pred_probs = ensemble_model.predict(validation_generator, steps=validation_steps)\n","# y_pred = np.argmax(y_pred_probs, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4d7GP9ToqSsr"},"outputs":[],"source":["# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# # Calculate evaluation metrics\n","# accuracy = accuracy_score(y_true, y_pred)\n","# precision = precision_score(y_true, y_pred, average='weighted')\n","# recall = recall_score(y_true, y_pred, average='weighted')\n","# f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","# print(f'Accuracy: {accuracy}')\n","# print(f'Precision: {precision}')\n","# print(f'Recall: {recall}')\n","# print(f'F1 Score: {f1}')\n","\n","# # Display classification report and confusion matrix\n","# class_names = list(class_mapping.values())\n","# print(\"\\nClassification Report:\")\n","# print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","# print(\"\\nConfusion Matrix:\")\n","# conf_matrix = confusion_matrix(y_true, y_pred)\n","# print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psO9iGjcSU1L"},"outputs":[],"source":["# Save the trained model\n","# model.save('plant_classification_model_transfer.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dR8p9hQBGfs9"},"outputs":[],"source":["# Load the model for inference\n","# loaded_model = keras.models.load_model('plant_classification_model_transfer.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fpSc0MRGi-4"},"outputs":[],"source":["# Example code for prediction on a new image\n","def predict_plant(image_path):\n","    img = image.load_img(image_path, target_size=input_shape[:2])\n","    img = image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img /= 255.0\n","\n","    prediction = loaded_model.predict(img)\n","    class_index = np.argmax(prediction)\n","    plant_name = class_mapping.get(class_index, 'Unknown Plant')\n","    confidence = np.max(prediction)\n","\n","    return plant_name, confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pcfmXz6GlzL"},"outputs":[],"source":["# Example usage:\n","image_path = '/content/aloe.jpg'\n","predicted_plant, confidence = predict_plant(image_path)\n","print(f\"Predicted plant: {predicted_plant}\")\n","print(f\"Confidence level: {confidence * 100:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qS-NCgUL43OM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1pVoDdtsPlMyPxJTzLqNMZz78YtEtW9Zu","timestamp":1714310438591}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}